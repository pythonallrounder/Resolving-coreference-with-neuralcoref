{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "34b430d0f6e2128ba41cb4b20f86d4b35a292804"
   },
   "source": [
    "# Resolving coreference with neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3cd8d3d1beaed38a23ad376fe7e8ef1d6413c330"
   },
   "source": [
    "There are few out-of-the-box libraries that support or specifically built for coreference resolution. Most wide-known are [CoreNLP](https://stanfordnlp.github.io/CoreNLP/coref.html), [Apache OpenNLP](https://opennlp.apache.org/) and [neuralcoref](https://github.com/huggingface/neuralcoref). In this short notebook, we will explore neuralcoref 3.0, a coreference resolution library by Huggingface.\n",
    "\n",
    "First, let's install neuralcoref 3.0. To do this, we need to slightly downgrade spacy (neuralcoref is not compatible with the new cymem version used by the current version of spacy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "dccc13e0424709632d2a8d8b40ffd1031cac9dc1"
   },
   "outputs": [],
   "source": [
    "MODEL_URL = \"https://github.com/huggingface/neuralcoref-models/releases/\" \\\n",
    "            \"download/en_coref_md-3.0.0/en_coref_md-3.0.0.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d21ebadafb3a5a32240e236f29361f09103fef4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install spacy==2.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "39bea3da8166b8517ac1be5b5faf35c0a08ac635",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/huggingface/neuralcoref-models/releases/download/en_coref_md-3.0.0/en_coref_md-3.0.0.tar.gz\n",
      "  Downloading https://github.com/huggingface/neuralcoref-models/releases/download/en_coref_md-3.0.0/en_coref_md-3.0.0.tar.gz (161.3 MB)\n",
      "Requirement already satisfied: spacy>=>=2.0.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from en-coref-md==3.0.0) (2.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\PROGRA~1\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-yr5uhnm9\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\PROGRA~1\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-yr5uhnm9\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\PROGRA~1\\AppData\\Local\\Temp\\pip-wheel-swjrdsw_'\n",
      "       cwd: C:\\Users\\PROGRA~1\\AppData\\Local\\Temp\\pip-req-build-yr5uhnm9\\\n",
      "  Complete output (51 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.7\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\n",
      "  copying en_coref_md\\__init__.py -> build\\lib.win-amd64-3.7\\en_coref_md\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "  copying en_coref_md\\neuralcoref\\__init__.py -> build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "  copying en_coref_md\\__init__.pxd -> build\\lib.win-amd64-3.7\\en_coref_md\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\meta.json -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\tokenizer -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\ner\\cfg -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\ner\\lower_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\ner\\moves -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\ner\\tok2vec_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\ner\\upper_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (0.8.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (1.18.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (47.1.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=>=2.0.0->en-coref-md==3.0.0) (7.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=>=2.0.0->en-coref-md==3.0.0) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=>=2.0.0->en-coref-md==3.0.0) (3.3.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=>=2.0.0->en-coref-md==3.0.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=>=2.0.0->en-coref-md==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=>=2.0.0->en-coref-md==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=>=2.0.0->en-coref-md==3.0.0) (2020.6.20)\n",
      "Building wheels for collected packages: en-coref-md\n",
      "  Building wheel for en-coref-md (setup.py): started\n",
      "  Building wheel for en-coref-md (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for en-coref-md\n",
      "Failed to build en-coref-md\n",
      "Installing collected packages: en-coref-md\n",
      "    Running setup.py install for en-coref-md: started\n",
      "    Running setup.py install for en-coref-md: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\cfg -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\pairs_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\single_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\\key2row -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\\vectors -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\\key2row -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\\vectors -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\parser\\cfg -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\parser\\lower_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\parser\\moves -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\parser\\tok2vec_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\parser\\upper_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\tagger\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\tagger\\cfg -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\tagger\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\tagger\\model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\tagger\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\tagger\\tag_map -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\tagger\n",
      "  creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\vocab\\key2row -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\vocab\\lexemes.bin -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\vocab\\strings.json -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "  copying en_coref_md\\en_coref_md-3.0.0\\vocab\\vectors -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "  copying en_coref_md\\meta.json -> build\\lib.win-amd64-3.7\\en_coref_md\n",
      "  copying en_coref_md\\neuralcoref\\neuralcoref.pyx -> build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "  copying en_coref_md\\neuralcoref\\neuralcoref.pxd -> build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "  copying en_coref_md\\neuralcoref\\__init__.pxd -> build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "  running build_ext\n",
      "  building 'en_coref_md.neuralcoref.neuralcoref' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for en-coref-md\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\PROGRA~1\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-yr5uhnm9\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\PROGRA~1\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-yr5uhnm9\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\PROGRA~1\\AppData\\Local\\Temp\\pip-record-mgbe8zyd\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\Include\\en-coref-md'\n",
      "         cwd: C:\\Users\\PROGRA~1\\AppData\\Local\\Temp\\pip-req-build-yr5uhnm9\\\n",
      "    Complete output (51 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.7\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\n",
      "    copying en_coref_md\\__init__.py -> build\\lib.win-amd64-3.7\\en_coref_md\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "    copying en_coref_md\\neuralcoref\\__init__.py -> build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "    copying en_coref_md\\__init__.pxd -> build\\lib.win-amd64-3.7\\en_coref_md\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\meta.json -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\tokenizer -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\ner\\cfg -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\ner\\lower_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\ner\\moves -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\ner\\tok2vec_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\ner\\upper_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\ner\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\cfg -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\pairs_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\single_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\\key2row -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\\vectors -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\static_vectors\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\\key2row -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\\vectors -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\neuralcoref\\tuned_vectors\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\parser\\cfg -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\parser\\lower_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\parser\\moves -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\parser\\tok2vec_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\parser\\upper_model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\parser\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\tagger\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\tagger\\cfg -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\tagger\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\tagger\\model -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\tagger\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\tagger\\tag_map -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\tagger\n",
      "    creating build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\vocab\\key2row -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\vocab\\lexemes.bin -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\vocab\\strings.json -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "    copying en_coref_md\\en_coref_md-3.0.0\\vocab\\vectors -> build\\lib.win-amd64-3.7\\en_coref_md\\en_coref_md-3.0.0\\vocab\n",
      "    copying en_coref_md\\meta.json -> build\\lib.win-amd64-3.7\\en_coref_md\n",
      "    copying en_coref_md\\neuralcoref\\neuralcoref.pyx -> build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "    copying en_coref_md\\neuralcoref\\neuralcoref.pxd -> build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "    copying en_coref_md\\neuralcoref\\__init__.pxd -> build\\lib.win-amd64-3.7\\en_coref_md\\neuralcoref\n",
      "    running build_ext\n",
      "    building 'en_coref_md.neuralcoref.neuralcoref' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\PROGRA~1\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-yr5uhnm9\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\PROGRA~1\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-yr5uhnm9\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\PROGRA~1\\AppData\\Local\\Temp\\pip-record-mgbe8zyd\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\Include\\en-coref-md' Check the logs for full command output.\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install {MODEL_URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b6add210e335049ff401ea6b7240811c2de3c296",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_md==2.3.1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Programmer\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz (50.8 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from en_core_web_md==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.50.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (47.1.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.3.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.6.20)\n",
      "Building wheels for collected packages: en-core-web-md\n",
      "  Building wheel for en-core-web-md (setup.py): started\n",
      "  Building wheel for en-core-web-md (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-md: filename=en_core_web_md-2.3.1-py3-none-any.whl size=50916645 sha256=a231b06e60c8d8f8e5036f0fe5dc991df05bdfe36fd715bfcaa00e7f3761a539\n",
      "  Stored in directory: C:\\Users\\PROGRA~1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-8i_tzylk\\wheels\\43\\1d\\c1\\a0af68d0648debf57f875e9dda56bbac35cfc27bfa187ffc46\n",
      "Successfully built en-core-web-md\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-2.3.1\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29a6a0eaf7e34c05561a9d39f8b58ea1172238c8"
   },
   "source": [
    "## A small neuralcoref tutorial\n",
    "\n",
    "How does this lib work? Let's find out!\n",
    "\n",
    "First,we need to load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "48625f34cd128548af8df600c793911588fef8e0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import en_core_web_md\n",
    "import neuralcoref\n",
    "nlp =en_core_web_md.load()\n",
    "#neuralcoref.add_to_pipe(nlp)\n",
    "#coref = neuralcoref.NeuralCoref(nlp.vocab)\n",
    "#nlp.add_pipe(coref, name='neuralcoref')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bb582847e39d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'context'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'token' is not defined"
     ]
    }
   ],
   "source": [
    "#token.set_extension('context', default=False, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "305f83497538e208dd7bf2fc4a7ec65562b8d2bb"
   },
   "source": [
    "Now we need a sentence with coreference. \n",
    "\n",
    "A boring theoretical reminder: coreference happens when* two different words denote the same entity* in the real world. In this competition, we deal with pronomial coreference. It comes in two flavors:\n",
    "1. *Anaphora*, when a pronoun follows a noun: \"John looked at me. He was clearly angry\".\n",
    "2. *Cataphora*, when it is vice versa: \"When she opened the door, Jane realized that it was cold outside\"\n",
    "\n",
    "Let's start with two simple sentences with two anaphoric coreferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "17027beaecc819c4b7ed65f3361db7dcd5df5e03"
   },
   "outputs": [],
   "source": [
    "#test_sent = \"The doctor came in. She held a paper in her hand.\"\n",
    "test_sent = \"Cook it on a barbeque till cooked.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2aa81a40ec8f2f134d52e1ebbc4db7478927d280"
   },
   "source": [
    "Using neuralcoref is not really different from using plain spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3569e52400145d21454ee55f866f2380b555e6af"
   },
   "outputs": [],
   "source": [
    "doc = nlp(test_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1cec6a87de6b380075ebfc6d6564657e9704a65d"
   },
   "source": [
    "To check if any kind of coreference was detected, `has_coref` attribute of the extension (referred to as `_`) is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "b6230257c638f1731ffa0c5585be03f478b8789c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.has_coref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1c2b01e14ab88329a1d2b9724f95f03cae91546"
   },
   "source": [
    "Great! We found something, let's see what exactly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "0f49d40ca6e2427972548cdee82dbab6171cbe43"
   },
   "outputs": [],
   "source": [
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6867f381febdf491260ce718841e961156e5b407"
   },
   "source": [
    "You can go to the [website](https://huggingface.co/coref/?text=The%20doctor%20came%20in.%20She%20held%20a%20paper%20in%20her%20hand.) and play with the tool. It outputs cool resolution graphs like this one:\n",
    "\n",
    "![graph](http://i66.tinypic.com/wtbmdi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f9101c48de7d0448f4d7139fbdc8f7838df2ff3"
   },
   "source": [
    "You can get the entity and coreferring pronouns from these clusters by simple indexing. The objects returned are in fact ordinary spacy `span`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "eb60debe14ba56f8d0a9a8be28e66fe0b1eacb53"
   },
   "outputs": [],
   "source": [
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "24c010a396ccda9108c95c0fb3c7577533e042a5"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9d98cf0da160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoref_clusters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmentions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#doc._.coref_clusters[0].mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "612fd0bfdbb703f6a9ca42bae9d472beb53aae72"
   },
   "source": [
    "## Deciding which entity the pronoun refers to\n",
    "\n",
    "In competition data, the position of the entities and the pronoun comes as an offset from the beginning. Let's write a small function that will resolve coreference in a string and decide whether any of detected coreferring entities correspond to given offsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "fd193d52996eecefb90267a82ccb41f1d4d27fc7"
   },
   "outputs": [],
   "source": [
    "def is_inside(offset, span):\n",
    "    return offset >= span[0] and offset <= span[1]\n",
    "\n",
    "def is_a_mention_of(sent, pron_offset, entity_offset_a, entity_offset_b):\n",
    "    doc = nlp(sent)\n",
    "    if doc._.has_coref:\n",
    "        for cluster in doc._.coref_clusters:\n",
    "            main = cluster.main\n",
    "            main_span = main.start_char, main.end_char\n",
    "            mentions_spans = [(m.start_char, m.end_char) for m in cluster.mentions \\\n",
    "                              if (m.start_char, m.end_char) != main_span]\n",
    "            if is_inside(entity_offset_a, main_span) and \\\n",
    "                    np.any([is_inside(pron_offset, s) for s in mentions_spans]):\n",
    "                return \"A\"\n",
    "            elif is_inside(entity_offset_b, main_span) and \\\n",
    "                    np.any([is_inside(pron_offset, s) for s in mentions_spans]):\n",
    "                return \"B\"\n",
    "            else:\n",
    "                return \"NEITHER\"\n",
    "    else:\n",
    "        return \"NEITHER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39594a0d4ae0587a5b1e6ae88e869642fdb2610a"
   },
   "source": [
    "A small test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "95c9b8276cc1d4b60788581c71c7f5adaf6f32c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEITHER'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"The doctor came in. She held a paper in her hand.\"\n",
    "import neuralcoref \n",
    "entity_offset_a = test_sent.index(\"cook\")\n",
    "entity_offset_b = test_sent.index(\"barbeque\")\n",
    "pron_offset = test_sent.index(\"cooked\")\n",
    "\n",
    "is_a_mention_of(test_sent, pron_offset, entity_offset_a, entity_offset_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c825300783a95958ab0c16090aba71c7525ca890"
   },
   "source": [
    "## Testing on the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "4640e87f1d9faf87992ff2f250c0b92dd0408d96"
   },
   "outputs": [],
   "source": [
    "gap_train = pd.read_csv(\"https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\", \n",
    "                       delimiter='\\t', index_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "809284702660c75bf20ac2cc469da89f03b6a6d7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test-1</th>\n",
       "      <td>Upon their acceptance into the Kontinental Hoc...</td>\n",
       "      <td>His</td>\n",
       "      <td>383</td>\n",
       "      <td>Bob Suter</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "      <td>Dehner</td>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-2</th>\n",
       "      <td>Between the years 1979-1981, River won four lo...</td>\n",
       "      <td>him</td>\n",
       "      <td>430</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>353</td>\n",
       "      <td>True</td>\n",
       "      <td>Alfredo Di St*fano</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-3</th>\n",
       "      <td>Though his emigration from the country has aff...</td>\n",
       "      <td>He</td>\n",
       "      <td>312</td>\n",
       "      <td>Ali Aladhadh</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>Saddam</td>\n",
       "      <td>295</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-4</th>\n",
       "      <td>At the trial, Pisciotta said: ``Those who have...</td>\n",
       "      <td>his</td>\n",
       "      <td>526</td>\n",
       "      <td>Alliata</td>\n",
       "      <td>377</td>\n",
       "      <td>False</td>\n",
       "      <td>Pisciotta</td>\n",
       "      <td>536</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-5</th>\n",
       "      <td>It is about a pair of United States Navy shore...</td>\n",
       "      <td>his</td>\n",
       "      <td>406</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>421</td>\n",
       "      <td>True</td>\n",
       "      <td>Rock Reilly</td>\n",
       "      <td>559</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Chasers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text Pronoun  \\\n",
       "ID                                                                  \n",
       "test-1  Upon their acceptance into the Kontinental Hoc...     His   \n",
       "test-2  Between the years 1979-1981, River won four lo...     him   \n",
       "test-3  Though his emigration from the country has aff...      He   \n",
       "test-4  At the trial, Pisciotta said: ``Those who have...     his   \n",
       "test-5  It is about a pair of United States Navy shore...     his   \n",
       "\n",
       "        Pronoun-offset             A  A-offset  A-coref                   B  \\\n",
       "ID                                                                            \n",
       "test-1             383     Bob Suter       352    False              Dehner   \n",
       "test-2             430        Alonso       353     True  Alfredo Di St*fano   \n",
       "test-3             312  Ali Aladhadh       256     True              Saddam   \n",
       "test-4             526       Alliata       377    False           Pisciotta   \n",
       "test-5             406         Eddie       421     True         Rock Reilly   \n",
       "\n",
       "        B-offset  B-coref                                             URL  \n",
       "ID                                                                         \n",
       "test-1       366     True      http://en.wikipedia.org/wiki/Jeremy_Dehner  \n",
       "test-2       390    False    http://en.wikipedia.org/wiki/Norberto_Alonso  \n",
       "test-3       295    False           http://en.wikipedia.org/wiki/Aladhadh  \n",
       "test-4       536     True  http://en.wikipedia.org/wiki/Gaspare_Pisciotta  \n",
       "test-5       559    False            http://en.wikipedia.org/wiki/Chasers  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "74d94bd3a9b73f5cc6772183c8d4251cabd955ef"
   },
   "outputs": [],
   "source": [
    "def predict(df):\n",
    "    pred = pd.DataFrame(index=df.index, columns=[\"A\", \"B\", \"NEITHER\"]).fillna(False)\n",
    "    for i, row in tqdm_notebook(df.iterrows()):\n",
    "        pred.at[i, is_a_mention_of(row[\"Text\"], row[\"Pronoun-offset\"], row[\"A-offset\"], row[\"B-offset\"])] = True\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "719d2ee9badda7b27568f60a4ceb4fac197c51bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f097705d301d4110a9dd9c493ff8348a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_preds = predict(gap_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "80bed3afe200b73a8053487ef84a3f528b714891"
   },
   "outputs": [],
   "source": [
    "gap_train[\"NEITHER\"] = np.logical_and(~gap_train[\"A-coref\"], ~gap_train[\"B-coref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "3b014366fa3c0988cb9915c01fe745d16d2fda2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1082</td>\n",
       "      <td>1145</td>\n",
       "      <td>1773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A-coref B-coref NEITHER\n",
       "count     2000    2000    2000\n",
       "unique       2       2       2\n",
       "top      False   False   False\n",
       "freq      1082    1145    1773"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap_train[[\"A-coref\", \"B-coref\", \"NEITHER\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "454adf9427435bccc3e6e45083fc37c119e2f73d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A      B NEITHER\n",
       "count    2000   2000    2000\n",
       "unique      1      1       1\n",
       "top     False  False    True\n",
       "freq     2000   2000    2000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "6025f65f89874b5c9bcee95d88403a1d4ecb9b07",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       918\n",
      "           1       0.00      0.00      0.00       855\n",
      "           2       0.11      1.00      0.20       227\n",
      "\n",
      "   micro avg       0.11      0.11      0.11      2000\n",
      "   macro avg       0.04      0.33      0.07      2000\n",
      "weighted avg       0.01      0.11      0.02      2000\n",
      " samples avg       0.11      0.11      0.11      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\programmer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(gap_train[[\"A-coref\", \"B-coref\", \"NEITHER\"]], train_preds[[\"A\", \"B\", \"NEITHER\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88286f6644a16532a99cc9bde8ab25252e62dd37"
   },
   "source": [
    "We can see that though precision is quite good, we have very low recall. What can be done?\n",
    "1. Remove excessive sentenes: if entities and the pronoun are contained in two sentences, we can strip other sentences.\n",
    "2. Use neuralcoref's verdicts as a feature for another classifier (we would have to transform verdicts into probabilities anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
